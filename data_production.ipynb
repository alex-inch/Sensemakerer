{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection/Production\n",
    "\n",
    "This notebook collects a series of email newsletters (Tortoise's Sensemakers), then cleans them up, formats them as prompt-completion pairs, then runs bash commands using the OpenAI API to fine tune a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mailbox\n",
    "import re\n",
    "import email.header\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rendered matching emails using google Takeout\n",
    "mbox = mailbox.mbox('data/mail/sensemaker.mbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Older emails have extremely long \"---------\" line breaks of differing lengths\n",
    "all_dashes = re.compile('-{2,}')\n",
    "\n",
    "def clean_email(decoded, subject):\n",
    "    if 'Long stories short' in decoded: # Used as intro to top in ~90% of emails\n",
    "        body = decoded.split('Long stories short')[1]\n",
    "    else:\n",
    "        body = ''.join(all_dashes.split(decoded)[1:])\n",
    "\n",
    "    if subject not in body:\n",
    "        return None # Only lose ~15 articles, and ensures the start of the content is on-topic\n",
    "    \n",
    "    # Cleaning up unicode mess\n",
    "    body = ''.join(re.split(f'({subject})', body)[1:])\n",
    "    body.split(subject)\n",
    "    body = body.strip(' -\\r\\n')\n",
    "    body = body.replace('\\r', '')\n",
    "    body = body.replace('*', '')\n",
    "    body = all_dashes.sub('', body)\n",
    "    body = body.split('http')[0].strip('\\n ()')\n",
    "    return body\n",
    "\n",
    "def decode_mime(string):\n",
    "    return u''.join(\n",
    "        word.decode(encoding or 'utf8') if isinstance(word, bytes) else word\n",
    "        for word, encoding in email.header.decode_header(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "for msg in mbox:\n",
    "    subj = decode_mime(msg['subject'])\n",
    "\n",
    "    content = msg.get_payload()[0]\n",
    "    decoded = content.get_payload(decode=True).decode(content.get_content_charset())\n",
    "    cleaned = clean_email(decoded, subj)\n",
    "    if cleaned is None:\n",
    "        continue\n",
    "\n",
    "    data = {\n",
    "        'prompt': f'{subj}\\n\\n###\\n\\n',\n",
    "        'completion': f' {cleaned}###'\n",
    "    }\n",
    "    training_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out shorter completions\n",
    "df = pd.DataFrame(training_data)\n",
    "df['len'] = df['completion'].apply(len)\n",
    "df = df[df['len'] > 1000]\n",
    "\n",
    "df[['prompt', 'completion']].to_json('ft_data.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data is suitable\n",
    "!openai tools fine_tunes.prepare_data -f ft_data.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune Davinci model using training data\n",
    "!openai api fine_tunes.create -t \"ft_data.jsonl\" -m davinci --suffix \"sensemakerer\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intelligence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad191cfbf0a8581ccb64bebc713710259fb819e8ffc7cac45059827a36c9eca5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
